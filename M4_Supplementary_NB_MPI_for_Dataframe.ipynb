{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vchandraiitk/PokerCardGame/blob/master/M4_Supplementary_NB_MPI_for_Dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heated-queens"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Supplementary Notebook: Implementation of send and receive operation on a dataset using MPI"
      ],
      "id": "heated-queens"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "military-proportion"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "military-proportion"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "durable-grounds"
      },
      "source": [
        "At the end of the mini-project, you will be able to :\n",
        "\n",
        "* implement the collective communication operations like scatter, gather, broadcast on a dataset using MPI"
      ],
      "id": "durable-grounds"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "growing-queens"
      },
      "source": [
        "### Dataset"
      ],
      "id": "growing-queens"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raised-connection"
      },
      "source": [
        "Here, we will be using the “Iris dataset”.The Iris dataset contains 50 samples of 3 different species of iris (150 samples total).\n",
        "\n",
        "The columns in this dataset are:\n",
        "\n",
        "- SepalLength (cm)\n",
        "- SepalWidth (cm)\n",
        "- PetalLength (cm)\n",
        "- PetalWidth (cm)\n",
        "- Species"
      ],
      "id": "raised-connection"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "global-savings"
      },
      "source": [
        "**Note:** We will be using the mpi4py Python package for MPI based code implementation"
      ],
      "id": "global-savings"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "green-deviation"
      },
      "source": [
        "**Run the below code to install mpi4py package**"
      ],
      "id": "green-deviation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "designing-marketing",
        "scrolled": true
      },
      "source": [
        "!pip install mpi4py"
      ],
      "id": "designing-marketing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedicated-thong"
      },
      "source": [
        "#### Importing Necessary Packages"
      ],
      "id": "dedicated-thong"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reported-acrobat",
        "scrolled": true
      },
      "source": [
        "# Importing pandas\n",
        "import pandas as pd\n",
        "# Importing Numpy\n",
        "import numpy as np\n",
        "# Importing MPI from mpi4py package\n",
        "from mpi4py import MPI\n",
        "# Importing sqrt function from the Math\n",
        "from math import sqrt\n",
        "# Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "import time\n",
        "from sklearn import datasets"
      ],
      "id": "reported-acrobat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "universal-jonathan",
        "scrolled": true,
        "cellView": "form"
      },
      "source": [
        "#@title Downloading the data\n",
        "iris = datasets.load_iris()\n",
        "dataset = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "dataset['species'] = iris.target\n",
        "dataset['species'] = dataset['species'].apply(lambda x: iris.target_names[x])\n",
        "dataset.to_csv('iris_dataset.csv', index=False)\n",
        "print(\"Dataset downloaded successfully!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "universal-jonathan"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "early-peace"
      },
      "source": [
        "### Load data\n",
        "\n",
        "Write a function that takes the filename as input and loads the data in a pandas dataframe."
      ],
      "id": "early-peace"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "differential-vacation",
        "scrolled": true
      },
      "source": [
        "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
        "# Defining a function to load the data\n",
        "def loadData(filename):\n",
        "    # Loading the dataset with column names as\n",
        "    data = pd.read_csv(filename)\n",
        "    # Returning the dataframe\n",
        "    return data\n",
        "# Calling the function loadData and storing the dataframe in a variable named df\n",
        "df = loadData(FILENAME)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "differential-vacation"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Point-to-point Blocking Communication"
      ],
      "metadata": {
        "id": "bi0E5wjVUf4Y"
      },
      "id": "bi0E5wjVUf4Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passing the entire Dataframe**"
      ],
      "metadata": {
        "id": "3YpLjFRGWzlP"
      },
      "id": "3YpLjFRGWzlP"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile passing_dataframe.py\n",
        "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Defining a function\n",
        "\n",
        "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
        "# Defining a function to load the data\n",
        "def loadData(filename):\n",
        "    # Loading the dataset with column names as\n",
        "    data = pd.read_csv(filename)\n",
        "    # Returning the dataframe\n",
        "    return data\n",
        "# Calling the function loadData and storing the dataframe in a variable named df\n",
        "df = loadData(FILENAME)\n",
        "\n",
        "def main():\n",
        "    # Creating a communicator\n",
        "    comm = MPI.COMM_WORLD\n",
        "    # number of the process running the code\n",
        "    rank = comm.Get_rank()\n",
        "    # total number of processes running\n",
        "    size = comm.Get_size()\n",
        "    # master process\n",
        "    if rank == 0:\n",
        "        # Generate a dictionary with arbitrary data in it\n",
        "        data = df\n",
        "        # master process sends data to worker processes by\n",
        "        # going through the ranks of all worker processes\n",
        "        for i in range(1, size):\n",
        "            # Sending data\n",
        "            comm.send(data, dest=i, tag=i)\n",
        "            # Displaying the results\n",
        "            print('Process {} sent data:'.format(rank), data)\n",
        "    # worker processes\n",
        "    else:\n",
        "        # each worker process receives data from master process\n",
        "        data = comm.recv(source=0, tag=rank)\n",
        "        # Displaying the results\n",
        "        print('Process {} received data:'.format(rank), data)\n",
        "# Calling the function\n",
        "main()"
      ],
      "metadata": {
        "id": "keiEqxNFSEwY"
      },
      "id": "keiEqxNFSEwY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root -np 4 python passing_dataframe.py"
      ],
      "metadata": {
        "id": "pFg8vnR8TPpO"
      },
      "id": "pFg8vnR8TPpO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collective Communication\n",
        "\n",
        "In MPI for Python, the `Comm.Bcast`, `Comm.Scatter`, `Comm.Gather`, `Comm.Allgather`, `Comm.Alltoall` methods provide support for collective communications of memory buffers. The lower-case variants `Comm.bcast`, `Comm.scatter`, `Comm.gather`, `Comm.allgather` and `Comm.alltoall` can communicate general Python objects."
      ],
      "metadata": {
        "id": "qD2RmEKDXLb_"
      },
      "id": "qD2RmEKDXLb_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Broadcasting the entire Dataframe**"
      ],
      "metadata": {
        "id": "5__NCyrAZZo0"
      },
      "id": "5__NCyrAZZo0"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile BroadcastingDataframe.py\n",
        "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
        "# Defining a function to load the data\n",
        "def loadData(filename):\n",
        "    # Loading the dataset with column names as\n",
        "    data = pd.read_csv(filename)\n",
        "    # Returning the dataframe\n",
        "    return data\n",
        "# Calling the function loadData and storing the dataframe in a variable named df\n",
        "df = loadData(FILENAME)\n",
        "\n",
        "# Defining a function\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD\n",
        "    id = comm.Get_rank()            #number of the process running the code\n",
        "    numProcesses = comm.Get_size()  #total number of processes running\n",
        "    if id == 0:\n",
        "        # Generate a dictionary with arbitrary data in it\n",
        "        data = df\n",
        "    else:\n",
        "        # start with empty data\n",
        "        data = None\n",
        "    # Broadcasting the data\n",
        "    data = comm.bcast(data, root=0)\n",
        "    # Printing the data along with the id number\n",
        "    print('Rank: ', id,', received data: ' , data, '\\n')\n",
        "\n",
        "# Calling a function\n",
        "main()"
      ],
      "metadata": {
        "id": "THdnsUfeZecF"
      },
      "id": "THdnsUfeZecF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --allow-run-as-root -np 4 python BroadcastingDataframe.py"
      ],
      "metadata": {
        "id": "ilxQQHXsZeZM"
      },
      "id": "ilxQQHXsZeZM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Scatter Operation on the Dataframe**\n",
        "\n",
        "- Create a function to divide the dataframe equally among different processes.\n",
        "- Perform scatter operation"
      ],
      "metadata": {
        "id": "JfvkwghAa3Zu"
      },
      "id": "JfvkwghAa3Zu"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ScatteringDataframe.py\n",
        "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from decimal import Decimal, ROUND_HALF_UP # Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
        "\n",
        "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
        "# Defining a function to load the data\n",
        "def loadData(filename):\n",
        "    # Loading the dataset with column names as\n",
        "    data = pd.read_csv(filename)\n",
        "    # Returning the dataframe\n",
        "    return data\n",
        "# Calling the function loadData and storing the dataframe in a variable named df\n",
        "df = loadData(FILENAME)\n",
        "\n",
        "def dividing_data(dataset, size_of_workers):\n",
        "    #Divide the data among the workers\n",
        "    slice_for_each_worker = int(Decimal(dataset.shape[0]/size_of_workers).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))\n",
        "    print('Slice of data for each worker: {}'.format(slice_for_each_worker))\n",
        "    data_for_worker = []\n",
        "    for i in range(0, size_of_workers):\n",
        "        if i < size_of_workers - 1:\n",
        "            data_for_worker.append(dataset[slice_for_each_worker*i:slice_for_each_worker*(i+1)])\n",
        "        else:\n",
        "            data_for_worker.append(dataset[slice_for_each_worker*i:])\n",
        "    return data_for_worker\n",
        "\n",
        "# Defining a function\n",
        "def main():\n",
        "    # communicator\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()   # number of the process running the code\n",
        "    size = comm.Get_size()   # total number of processes running\n",
        "    data = None # Starting with an empty  data\n",
        "    if rank == 0:\n",
        "        # Creating a Numpy array.\n",
        "        data = dividing_data(df, size)\n",
        "    # scatter operation\n",
        "    received_data = comm.scatter(data, root=0)\n",
        "    # Displaying the result\n",
        "    print('Rank: ', rank, ', recvbuf: ', received_data)\n",
        "\n",
        "# Calling the main function\n",
        "main()"
      ],
      "metadata": {
        "id": "TmLefFkIbT5u"
      },
      "id": "TmLefFkIbT5u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --allow-run-as-root -np 4 python ScatteringDataframe.py"
      ],
      "metadata": {
        "id": "HiHTRijCbT23"
      },
      "id": "HiHTRijCbT23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Gather Operation on the Dataframe**"
      ],
      "metadata": {
        "id": "ybOD9TLilB67"
      },
      "id": "ybOD9TLilB67"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile GatherringDataframe.py\n",
        "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from decimal import Decimal, ROUND_HALF_UP # Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
        "\n",
        "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
        "# Defining a function to load the data\n",
        "def loadData(filename):\n",
        "    # Loading the dataset with column names as\n",
        "    data = pd.read_csv(filename)\n",
        "    # Returning the dataframe\n",
        "    return data\n",
        "# Calling the function loadData and storing the dataframe in a variable named df\n",
        "df = loadData(FILENAME)\n",
        "\n",
        "# Defining a function\n",
        "def main():\n",
        "    # communicator\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()   # number of the process running the code\n",
        "    size = comm.Get_size()   # total number of processes running\n",
        "    slice_for_each_worker = int(Decimal(df.shape[0]/size).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))   # Number of elements in a array for each rank\n",
        "    # Creating a sender buffer array\n",
        "    if rank < size-1:\n",
        "        sendbuf = df[slice_for_each_worker*rank:slice_for_each_worker*(rank+1)]\n",
        "    else:\n",
        "        sendbuf = df[slice_for_each_worker*rank:]\n",
        "    # Printing the result\n",
        "    print('Rank: ',rank, ', sendbuf: ', sendbuf)\n",
        "    recvbuf = None\n",
        "    # Gathering the Information\n",
        "    recvbuf = comm.gather(sendbuf, root = 0)\n",
        "    # Display the result\n",
        "    if rank == 0:\n",
        "        print('Rank: ',rank, ', recvbuf received: ', recvbuf)\n",
        "\n",
        "# Calling a function\n",
        "main()"
      ],
      "metadata": {
        "id": "JNgsoqyBlVLC"
      },
      "id": "JNgsoqyBlVLC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --allow-run-as-root -np 4 python GatherringDataframe.py"
      ],
      "metadata": {
        "id": "wChauhLFlYZu"
      },
      "id": "wChauhLFlYZu",
      "execution_count": null,
      "outputs": []
    }
  ]
}